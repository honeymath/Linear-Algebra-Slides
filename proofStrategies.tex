
\aaa{Before reviewing proof}


Make sure you are able to do QR decomposition, calculating determinant, calculating $A^n$, calculating $e^A$, able to solve differential equations $y'=Ay$, able to solve applicational problems (like the one in homework). 


Able to verify if a matrix is diagonalizable (by verifying if it satisfies a polynomial). Able to diagonalize a matrix, able to find Jordan canonical form.... 


You must be able to do all computations. In an efficient way.

\a{Eigenvalue and eigenvectors for 2 by 2 matrices}
Given 2 √ó 2 matrix. Its characteristic polynomial is given by
$$
‚Äúdet‚Äú\left(tI_2-\m ab,cd.\right) = t^2 - (a+d) t +(ad-bc)
$$
Suppose the polynomial is given by $(t-Œª_1)(t-Œª_2)$ with $Œª_1‚â†Œª_2$. In this case, it is diagonalizable.
\a\aa
Since $(A-Œª_1)(A-Œª_2)=0$, we have $A(A-Œª_1)=Œª_2(A-Œª_1)$ and $A(A-Œª_2)=Œª_1(A-Œª_2)$.

Therefore, the matrix
$$ \m {a-Œª_1}b,c{d-Œª_1}. ‚ê£  ‚Äúeigenmatrix of eigenvalue ‚ÄúŒª_2 $$
$$ \m {a-Œª_2}b,c{d-Œª_2}. ‚ê£  ‚Äúeigenmatrix of eigenvalue ‚ÄúŒª_1 $$

\a\aa

\exe Suppose $2a+b‚â†0$. Given the following matrix
$$
\m ba,{2b}{2a}.
$$
What is its eigenvalue and what is its eigenvector?

\a\aa
No matter what, this matrix is always \x{not invertible} since columns are colinear. Therefore, $0$ must be an eigenvalue of it. Therefore, by looking at the trace, the other eigenvalue must be $2a+b$.

Therefore $A-0I=\m ba,{2b}{2a}.$ is the eigenmatrix of eigenvalue $2a+b$

$A-(2a+b)I=\m{-2a}a,{2b}{-b}.$ is the eigenmatrix of eigenvalue $0$.

So
$$
\m1,2.
$$
is eigenvector of eigenvalue $2a+b$. And
$$
\m{a},{-b}.
$$
is an eigenvector of eigenvalue $0$.
\a\aa
Therefore, we can even write down its diagonalization
$$
\m1a,2{-b}.^{-1}\m ba,{2b}{2a}.\m1a,2{-b}.=\m{2a+b}0,00.
$$

\[rem]{When eigenvalues are given , finding eigenvectors is extremely easy, you should able to be compute within 10 seconds in mind.}

\a\aa
\exe Write down an eigenvector of the following matrix
$$
\m 0{-2},35.
$$
of eigen value $2$.


\a\aa
\exe Write down an eigenvector of the following matrix
$$
\m 3{4},37.
$$
of eigen value $9$.


\a{The most important fact}

\[thm]{If $P_1,‚Ä¶,P_n$ are projection matrices $P_i^2=P_i$ and
$$
P_1+‚Ä¶+P_n = I
$$
Then $P_iP_j=0$
}
\textbf{Proof} We consider a matrix
$$
Q = \m{P_1}{P_2}\cdots{P_n}.
$$
$$
R = \m{P_1},{P_2},\vdots,{P_n}. ‚ê£ S = \m{P_1}{}\cdots{},
{}{P_2}\cdots{},
{}{}\ddots{},
{}{}{}{P_n}.
$$
This definition implies that $QR=I$.
\a\aa
$$
RQ=\m{P_1^2}{P_1P_2}{\cdots}{P_1P_n},
{P_2P_1}{P_2^2}\cdots{P_2P_n},
\vdots\vdots\vdots\ddots\vdots,
{P_nP_1}{P_nP_2}\cdots{P_n^2}.
$$
Furthermore, $QS=Q$, $SR=R$. So 
$$
(S-RQ)^2=S^2-SRQ-RQS+RQRQ = S-RQ
$$
This implies $S-RQ$ is a projection matrix. However, $P_i^2=P_i$ so $‚Äútr‚Äú(S-RQ)=0$ ‚üπ   S-RQ=0 ‚üπ   $P_iP_j=0$.
\a\aa
\[thm]{Suppose $P_i\vec v_i =\vec v_i$ for $1‚â§i‚â§k$ and $P_iP_j=0$ for $1‚â§i,j‚â§k$. Then
$$
\vec v_1, ‚Ä¶, \vec v_k
$$
is linearly independent.}
For $i‚â†j$,
$$
P_i\vec v_j=P_iP_j\vec v_j=0
$$
So if
$$
a_1\vec v_1+‚Ä¶+a_k\vec v_k=0
$$
Multiply $P_i$ we have
$$
0+0+‚Ä¶+0+a_iP_i\vec v_i+0+\cdots = P_i0=0  ‚üπ   a_i\vec v_i=0 ‚üπ   a_i=0.
$$
\aaa
\aaa{Of different eigenvalue}

\exe Show that eigenvectors from different eigenvalue must be linearly independent.

Suppose $A\vec v_i=Œª_i\vec v_i$ with $Œª_i‚â†Œª_j$. Assume
$$
a_1\vec v_1+a_2\vec v_2+‚Ä¶+a_k\vec v_k = 0.
$$
Multiply by $A$, we have
$$
a_1Œª_1\vec v_1+a_2Œª_2\vec v_2+‚Ä¶+a_kŒª_k\vec v_k = 0.
$$
Subtract this equation by Œª times the first equation, we have
$$
a_2(Œª_2-Œª_1)\vec v_2+‚Ä¶+a_k(Œª_k-Œª_1)\vec v_k=0
$$
By induction hypothesis, $a_2=‚Ä¶=a_k=0$.
So $a_1\vec v_1=0$.
\a\aa
Proof by spectural decomposition. Assume $\vec v$ is an eigenvector of eigenvalue Œº
$$
(Œª+Œµ)ùí´_{Œª}\vec v=A ùí´ _{Œª}\vec v = ùí´_{Œª}A\vec v=  ùí´_{Œª}Œº\vec v
$$
This implies 
$$
(Œª-Œº+Œµ)ùí´_{Œª}\vec v=0
$$
If $Œª‚â†Œº$, this implies $ùí´_{Œª}\vec v=0$, in particular, taking constant part, we have $P_{Œª}\vec v=0$.
Therefore $P_{Œº_1}+‚Ä¶+P_{Œº_k}+P_Œª+‚Ä¶+P_{Œº_m}=I$, multiply $\vec v$ we have $P_{Œº}\vec v=\vec v.$
\aaa
\aaa{Some simple proof}
We have already proved eigenvectors of normal matrices are perpendicular each other. Now let us write some shorter proof for some cases.

\a\aa

\exe Let $A=A^H$ be Hermitian matrices, Show that eigenvectors of different eigenvalues of $A$ are automatically Hermitian orthogonal.

\sol Let $A\vec v=Œª\vec v$ and $A\vec w=Œº\vec w$ with  $Œª‚â†Œº$. Since $A=A^H$, $Œª,Œº$ are all real numbers.

$$
\vec v^H Œº\vec w = \vec v^HA\vec w = \vec v^HA^H\vec w = \vec v^H Œª\vec w.
$$

This implies that
$$
\vec v^H\vec w = 0.
$$
\a\aa

\exe Let $A=-A^H$ be skew Hermitian matrices, Show that eigenvectors of different eigenvalues of $A$ are automatically Hermitian orthogonal.

\sol Let $A\vec v=Œª\vec v$ and $A\vec w=Œº\vec w$ with  $Œª‚â†Œº$. Since $A=-A^H$, $¬ØŒª=-Œª,¬ØŒº=-Œº$ are all purely imaginary numbers.

$$
\vec v^H Œº\vec w = \vec v^HA\vec w = -\vec v^HA^H\vec w = -\vec v^H ¬ØŒª\vec w=\vec v^H Œª\vec w.
$$

\a\aa

\exe Let $A^{-1}=A^H$ be Unitary matrices, Show that eigenvectors of different eigenvalues of $A$ are automatically Hermitian orthogonal.

\sol Let $A\vec v=Œª\vec v$ and $A\vec w=Œº\vec w$ with  $Œª‚â†Œº$. Since $A^{-1}=A^H$, $¬ØŒª=\frac1{Œª},¬ØŒº=\frac1{Œº}$.

$$
\vec v^H Œº\vec w = \vec v^HA\vec w = \vec v^H(A^H)^{-1}\vec w = \vec v^H (¬Ø{Œª})^{-1}\vec w=\vec v^H Œª\vec w.
$$


\a\aa

\exe Let $AA^H=A^HA$ be Normal matrices, Show that eigenvectors of different eigenvalues of $A$ are automatically Hermitian orthogonal.

\sol We first prove a lemma. That if $AA^H=A^HA$, then $Ax=0$ implies $A^Hx = 0$. Indeed,
$$
Ax = 0 ‚üπ   x^HA^HAx = 0 ‚üπ   x^HAA^Hx = 0 ‚üπ   A^H x=0
$$
Therefore $Ax=Œªx ‚üπ  A^Hx = ¬Ø{Œª}x ‚üπ   x^HA = Œªx^H$.


$$
\vec v^H Œº\vec w = \vec v^HA\vec w = \vec v^H Œª\vec w.
$$


\a\aa

\exe Let $A=A^T$ be real, positive definite matrix. Then all eigenvalues of $A$ are positive

\sol If $Av = Œªv$, then $0<v^TAv = Œª\underbrace{v^Tv}_{>0}$ therefore $Œª>0$

\a{Exponential Functions}
$$
e^X=\lim_{n ‚ü∂  ‚àû}\left(1+\frac Xn\right)^n
$$

\[cor]{For any $X_1,X_2,‚Ä¶,X_k$
$$
\lim_{n ‚ü∂   ‚àû  }\left(1+\frac{X_1}n+\frac{X_2}{n^2}+‚Ä¶+\frac{X_k}{n^k}\right)^n = e^{X_1}
$$
In other words, all $X_2,‚Ä¶,X_k$ is ignorable.
}

\a\aa

\exe Show that if $A$ is real matrix, $A=A^T$ and all eigenvalues of $A$ are positive, then $A$ is positive definite.

\a\aa
\exe If $AB=BA$, then $e^Ae^B=e^{A+B}$

$$
e^Ae^B = \lim_{n ‚ü∂  ‚àû}(I+A/n)^n(I+B/n)^n = \lim_{n ‚ü∂  ‚àû}((I+A/n)(I+B/n))^n 
$$
$$= \lim_{n ‚ü∂  ‚àû}(I+(A+B)/n+AB/n^2)^n=e^{A+B}
$$

\a\aa
\exe If $A=-A^H$, show that $e^A$ is a unitary matrix

$$
e^A(e^{A})^H=e^Ae^{A^H}=e^{A+A^H}=e^0=I
$$
\a\aa
\exe If $A=A^H$, show that $e^A$ is a positive definite matrix.

Since $A=A^H$, all eigenvalues are real numbers. We have $(e^A)^H=e^{A^H}=e^A$. Also $e^A$ is a real matrix. Furthermore, the eigenvalue of $e^A$ is $e^Œª > 0 $. So $e^A$ is a real symmetric matrix with all positive eigenvalues, it is positive definite
\a\aa
\exe Show that any real positive definite matrix $A$ can be written as $e^X$ for a unique matrix $X$. We call this $X$ as $X=\ln A$

\a\aa
\exe Show that if $A$ $B$ are two positive definite matrix with $AB=BA$, then $AB$ is also a positive definite matrix.

$$
AB = e^{\ln A}e^{\ln B}=e^{\ln A+\ln B}
$$
so $AB$ is a positive definite matrix.
\a\aa
\exe If $A$ is a normal matrix. Show that $e^A$ admits a decomposition $e^A=PU$ where $P$ is a positive definite matrix, $U$ is a unitary matrix commute with $P$.
\aaa
\aaa{Eigenvalue and normal matrices}

Show that if $A$ is skew-Hermitian, then $e^A$ is unitary
\aaa
